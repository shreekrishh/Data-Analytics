{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": " sentiment analysis on movie reviews through NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreekrishh/Data-Analytics/blob/main/sentiment_analysis_on_movie_reviews_through_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "029908bd",
        "outputId": "c820fdb9-78f7-4b4a-b343-e570c567c062"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "id": "029908bd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv15KlAO5d8V",
        "outputId": "9f8f5402-2973-4d63-b54d-0589b50ec603"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "id": "Tv15KlAO5d8V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03cbd3ee"
      },
      "source": [
        "# read the data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/sentiment analysis on movie review using NLP/files/data/labelled_movie_reviews.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# shuffle the rows\n",
        "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n"
      ],
      "id": "03cbd3ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ac61d8",
        "outputId": "7c8106db-407a-4140-df27-6cbb0a2adef9"
      },
      "source": [
        "\n",
        "train_frac, val_frac, test_frac = 0.7, 0.1, 0.2\n",
        "Xr = df[\"text\"].tolist()\n",
        "Yr = df[\"label\"].tolist()\n",
        "train_end = int(train_frac*len(Xr))\n",
        "val_end = int((train_frac + val_frac)*len(Xr))\n",
        "\n",
        "\n",
        "data = dict(np.load(\"/content/drive/MyDrive/sentiment analysis on movie review using NLP/files/data/word_vectors.npz\",))\n",
        "\n",
        "\n",
        "w2v = {w:v for w, v in zip(data[\"words\"], data[\"vectors\"])}\n",
        "print(data['vectors'].shape)\n",
        "\n",
        "\n"
      ],
      "id": "b8ac61d8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(82197, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmkESZoUw5_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5f8a62-a3c7-4578-aa88-f6fca45c57dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "ZmkESZoUw5_w",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTc5qdth4Zct",
        "outputId": "ca290c33-a916-4d4d-d031-f6876a16f589"
      },
      "source": [
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#stopwords = stopwords.words('english')\n"
      ],
      "id": "VTc5qdth4Zct",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htrbUzpqWsSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce70344c-3cee-4b16-9655-05b8830d478d"
      },
      "source": [
        "unk = np.random.randn(*data[\"vectors\"][0].shape)\n",
        "unk.shape"
      ],
      "id": "htrbUzpqWsSh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ym2bU1Wa6iC"
      },
      "source": [
        "word_to_vec_dic = dict(zip(list(data[\"words\"]), list(data[\"vectors\"])))"
      ],
      "id": "-ym2bU1Wa6iC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad9bf7ab"
      },
      "source": [
        "# convert a document into a vector\n",
        "def document_to_vector(doc):\n",
        "  doc = re.sub(\"\\'\", \"\", doc)\n",
        "  doc = re.sub(\"[^a-zA-Z]\",\" \",doc)\n",
        "  doc = ' '.join(doc.split())\n",
        "  doc = doc.lower()\n",
        "  doc_tok= word_tokenize(doc)\n",
        "  # doc_tok = tok(doc)\n",
        "  filtered_words = list(set(doc_tok)-set(stopwords.words('english')))\n",
        "\n",
        "  for i in range(len(filtered_words)):\n",
        "    if filtered_words[i] in word_to_vec_dic:\n",
        "      filtered_words[i] = word_to_vec_dic.get(filtered_words[i])\n",
        "    else:\n",
        "      filtered_words[i] = unk\n",
        "  vec = np.mean(np.array(filtered_words), axis=0)\n",
        "  return vec\n",
        "\n",
        "df['vector of text'] = df['text'].apply(lambda x: document_to_vector(x))\n"
      ],
      "id": "ad9bf7ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlMpTXN_vx5r"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train,test = train_test_split(df, test_size=0.2)\n",
        "train,val = train_test_split(train, train_size = 0.875)\n",
        "X_train, Y_train = train['vector of text'], train['label']\n",
        "X_val, Y_val = val['vector of text'], val['label']\n",
        "X_test, Y_test = test['vector of text'],test['label']\n"
      ],
      "id": "GlMpTXN_vx5r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRsCIUVPy1zG"
      },
      "source": [
        "X_train = np.stack(X_train.values)\n",
        "Y_train = np.stack(Y_train.values)\n",
        "X_val = np.stack(X_val.values)\n",
        "Y_val = np.stack(Y_val.values)\n",
        "X_test = np.stack(X_test.values)\n",
        "Y_test = np.stack(Y_test.values)\n",
        "\n"
      ],
      "id": "SRsCIUVPy1zG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBzdi9B5fkv1"
      },
      "source": [
        "Y_train = (Y_train == 'pos').astype(int)\n",
        "Y_val = (Y_val== 'pos').astype(int)\n",
        "Y_test = (Y_test == 'pos').astype(int)\n"
      ],
      "id": "QBzdi9B5fkv1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72d7a922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83b5a4d-f535-4b2b-ed98-126b4c33cac1"
      },
      "source": [
        "\n",
        "C_set = [0.01,0.05,0.1, 0.3, 0.6, 1, 5,6,7, 10, 20, 25]\n",
        "for i in C_set:\n",
        "  lr=LogisticRegression(penalty='l2',max_iter=500,C=i,random_state=42) \n",
        "  def fit_model(Xtr, Ytr):\n",
        "    model=lr.fit(Xtr, Ytr)\n",
        "    return model\n",
        "  def test_model(model, Xtst, Ytst):\n",
        "    return model.score(Xtst, Ytst)\n",
        "  print(test_model(fit_model(X_train,Y_train), X_val, Y_val))\n",
        "\n",
        "    "
      ],
      "id": "72d7a922",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.813\n",
            "0.8344\n",
            "0.8402\n",
            "0.8468\n",
            "0.8498\n",
            "0.8496\n",
            "0.853\n",
            "0.8532\n",
            "0.8536\n",
            "0.8544\n",
            "0.8538\n",
            "0.854\n",
            "0.853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2m3f_4Fe9zt",
        "outputId": "cd4625d6-d3f9-4868-8b82-8e426abd0a05"
      },
      "source": [
        "#for C = 10, accuracy is maximum \n",
        "lr=LogisticRegression(penalty='l2',max_iter=500,C=10,random_state=42)\n",
        "test_model(fit_model(np.concatenate((X_train,X_val)),np.concatenate((Y_train,Y_val))),X_test,Y_test )"
      ],
      "id": "a2m3f_4Fe9zt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8562"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    }
  ]
}